import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import DataLoader
from torchvision import datasets, transforms

# Define the GraphConvolution layer
class GraphConvolution(nn.Module):
    def __init__(self, input_dim, output_dim):
        super(GraphConvolution, self).__init__()
        self.weight = nn.Parameter(torch.FloatTensor(input_dim, output_dim))
        self.bias = nn.Parameter(torch.FloatTensor(output_dim))

    def forward(self, x, adj):
        x = torch.matmul(adj, x)
        x = torch.matmul(x, self.weight)
        return x + self.bias

# Define the GCN model
class GCN(nn.Module):
    def __init__(self, input_dim, hidden_dim, output_dim):
        super(GCN, self).__init__()
        self.gc1 = GraphConvolution(input_dim, hidden_dim)
        self.gc2 = GraphConvolution(hidden_dim, output_dim)

    def forward(self, x, adj):
        x = F.relu(self.gc1(x, adj))
        x = self.gc2(x, adj)
        return F.log_softmax(x, dim=1)

# Construct the graph adjacency matrix
def construct_adjacency_matrix(image):
    num_pixels = image.size(0)
    adjacency = torch.zeros(num_pixels, num_pixels)
    
    # Define the spatial relationships (edges) based on the image structure
    # You can modify this part depending on your desired graph structure
    
    # Example: Connect each pixel to its 8 spatial neighbors (horizontal, vertical, and diagonal)
    for i in range(num_pixels):
        for j in range(num_pixels):
            if i > 0:
                adjacency[i, j] = 1  # Connect with the pixel above
                if j > 0:
                    adjacency[i, j] = 1  # Connect with the pixel above and to the left
                if j < num_pixels - 1:
                    adjacency[i, j] = 1  # Connect with the pixel above and to the right
            if i < num_pixels - 1:
                adjacency[i, j] = 1  # Connect with the pixel below
                if j > 0:
                    adjacency[i, j] = 1  # Connect with the pixel below and to the left
                if j < num_pixels - 1:
                    adjacency[i, j] = 1  # Connect with the pixel below and to the right
            if j > 0:
                adjacency[i, j] = 1  # Connect with the pixel to the left
            if j < num_pixels - 1:
                adjacency[i, j] = 1  # Connect with the pixel to the right
    
    return adjacency

# Set device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# Load and preprocess the data
transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5





####################################################################################################################################################
####################################################################################################################################################
####################################################################################################################################################

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import DataLoader
from torchvision import datasets, transforms

# Define the GraphConvolution layer
class GraphConvolution(nn.Module):
    def __init__(self, input_dim, output_dim):
        super(GraphConvolution, self).__init__()
        self.weight = nn.Parameter(torch.FloatTensor(input_dim, output_dim))
        self.bias = nn.Parameter(torch.FloatTensor(output_dim))

    def forward(self, x, adj):
        x = torch.matmul(adj, x)
        x = torch.matmul(x, self.weight)
        return x + self.bias

# Define the GCN model
class GCN(nn.Module):
    def __init__(self, input_dim, hidden_dim, output_dim):
        super(GCN, self).__init__()
        self.gc1 = GraphConvolution(input_dim, hidden_dim)
        self.gc2 = GraphConvolution(hidden_dim, output_dim)

    def forward(self, x, adj):
        x = F.relu(self.gc1(x, adj))
        x = self.gc2(x, adj)
        return F.log_softmax(x, dim=1)

# Construct the graph adjacency matrix
def construct_adjacency_matrix(image):
    num_pixels = image.size(0)
    adjacency = torch.zeros(num_pixels, num_pixels)
    
    # Define the spatial relationships (edges) based on the image structure
    # Here, we connect each pixel to its 8 spatial neighbors (horizontal, vertical, and diagonal)
    for i in range(num_pixels):
        for j in range(num_pixels):
            for p in range(-1, 2):
                for q in range(-1, 2):
                    if i + p >= 0 and i + p < num_pixels and j + q >= 0 and j + q < num_pixels:
                        adjacency[i * num_pixels + j, (i + p) * num_pixels + (j + q)] = 1
    
    return adjacency

# Set device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# Load and preprocess the data
transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize image tensors
])

train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)
test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)

train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)

# Define model parameters
input_dim = 32 * 32 * 3  # Assuming CIFAR-10 images are 32x32 with 3 channels
hidden_dim = 64
output_dim = 10  # Number of CIFAR-10 classes

# Create the GCN model
model = GCN(input_dim, hidden_dim, output_dim).to(device)

# Define optimizer and learning rate
optimizer = torch.optim.Adam(model.parameters(), lr=0.01)

# Training loop
num_epochs = 10
for

####################################################################################################################################################
####################################################################################################################################################
####################################################################################################################################################
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import DataLoader
from torchvision import datasets, transforms

# Define the GraphConvolution layer
class GraphConvolution(nn.Module):
    def __init__(self, input_dim, output_dim):
        super(GraphConvolution, self).__init__()
        self.weight = nn.Parameter(torch.FloatTensor(input_dim, output_dim))
        self.bias = nn.Parameter(torch.FloatTensor(output_dim))

    def forward(self, x, adj):
        x = torch.matmul(adj, x)
        x = torch.matmul(x, self.weight)
        return x + self.bias

# Define the GCN model
class GCN(nn.Module):
    def __init__(self, input_dim, hidden_dim, output_dim):
        super(GCN, self).__init__()
        self.gc1 = GraphConvolution(input_dim, hidden_dim)
        self.gc2 = GraphConvolution(hidden_dim, output_dim)

    def forward(self, x, adj):
        x = F.relu(self.gc1(x, adj))
        x = self.gc2(x, adj)
        return F.log_softmax(x, dim=1)

# Construct the graph adjacency matrix
def construct_adjacency_matrix(image):
    num_pixels = image.size(0)
    adjacency = torch.zeros(num_pixels, num_pixels)
    
    # Define the spatial relationships (edges) based on the image structure
    # Here, we connect each pixel to its 8 spatial neighbors (horizontal, vertical, and diagonal)
    for i in range(num_pixels):
        for j in range(num_pixels):
            for p in range(-1, 2):
                for q in range(-1, 2):
                    if i + p >= 0 and i + p < num_pixels and j + q >= 0 and j + q < num_pixels:
                        adjacency[i * num_pixels + j, (i + p) * num_pixels + (j + q)] = 1
    
    return adjacency

# Set device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# Load and preprocess the data
transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize image tensors
])

train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)
test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)

train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)

# Define model parameters
input_dim = 32 * 32 * 3  # Assuming CIFAR-10 images are 32x32 with 3 channels
hidden_dim = 64
output_dim = 10  # Number of CIFAR-10 classes

# Create the GCN model
model = GCN(input_dim, hidden_dim, output_dim).to(device)

# Define optimizer and learning rate
optimizer = torch.optim.Adam(model.parameters(), lr=0.01)

# Training loop
num_epochs = 10
for epoch in range(num_epochs):
    model.train()
    for batch_idx, (images, labels) in enumerate(train_loader):
        images = images.to(device)
        labels = labels.to(device)

        # Flatten the image tensors
        batch_size = images.size(0)
        images = images.view(batch_size, -1)

        # Construct adjacency matrices for the batch
        adj_matrices = []
        for
#######################################
# Training loop
num_epochs = 10
for epoch in range(num_epochs):
    model.train()
    for batch_idx, (images, labels) in enumerate(train_loader):
        images = images.to(device)
        labels = labels.to(device)

        # Flatten the image tensors
        batch_size = images.size(0)
        images = images.view(batch_size, -1)

        # Construct adjacency matrices for the batch
        adj_matrices = []
        for image in images:
            adjacency = construct_adjacency_matrix(image)
            adj_matrices.append(adjacency)
        adj_matrices = torch.stack(adj_matrices, dim=0).to(device)

        # Forward pass
        optimizer.zero_grad()
        outputs = model(images, adj_matrices)

        # Compute loss
        loss = F.nll_loss(outputs, labels)

        # Backward pass and optimization
        loss.backward()
        optimizer.step()

        if batch_idx % 100 == 0:
            print(f"Epoch: {epoch+1}/{num_epochs}, Batch: {batch_idx}/{len(train_loader)}, Loss: {loss.item()}")

    # Evaluate on the test set
    model.eval()
    with torch.no_grad():
        correct = 0
        total = 0
        for images, labels in test_loader:
            images = images.to(device)
            labels = labels.to(device)
            batch_size = images.size(0)
            images = images.view(batch_size, -1)
            adj_matrices = []
            for image in images:
                adjacency = construct_adjacency_matrix(image)
                adj_matrices.append(adjacency)
            adj_matrices = torch.stack(adj_matrices, dim=0).to(device)
            outputs = model(images, adj_matrices)
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()

        accuracy = 100 * correct / total
        print(f"Test Accuracy: {accuracy}%")




